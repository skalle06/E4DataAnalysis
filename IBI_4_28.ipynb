{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from zipfile import ZipFile\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utc_date_time(ts):\n",
    "    return pd.to_datetime(ts, unit='s', infer_datetime_format = True, utc = True)\n",
    "#.strftime('%H:%M:%S:%f')\n",
    "\n",
    "def add_fs(sample_rate, date):\n",
    "    return date + datetime.timedelta(milliseconds=1.0/(sample_rate) * 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_range(df_length, start_timestamp, sample_rate):\n",
    "    '''Generate date time range based on sample rate and starting timestamp'''\n",
    "    time_range = []\n",
    "    t_0 = get_utc_date_time(float(start_timestamp))\n",
    "    time_range.append(t_0)\n",
    "    \n",
    "    next_date = t_0\n",
    "    \n",
    "    for count in range(df_length-1):\n",
    "        next_date = add_fs(sample_rate, next_date)\n",
    "        time_range.append(next_date)\n",
    "    return time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    s = t.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    return s[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ibi(list_of_zips, participant_id):\n",
    "    ibi_all = []\n",
    "\n",
    "    for zip_file in list_of_zips:\n",
    "        zf = ZipFile(zip_file)\n",
    "        ibi_df_raw = pd.read_csv(zf.open('IBI.csv'), nrows=100)\n",
    "\n",
    "        starting_timestamp = get_utc_date_time(ibi_df_raw.columns[0])\n",
    "\n",
    "        new_cols = {ibi_df_raw.columns[0]: \"Timestamp\"}\n",
    "        ibi_df = ibi_df_raw.rename(columns=new_cols)\n",
    "        ibi_df['Participant ID'] = participant_id\n",
    "\n",
    "        ibi_df['Timestamp'] = ibi_df.apply(lambda x: starting_timestamp + pd.Timedelta(seconds=x['Timestamp']), axis=1)\n",
    "        ibi_df['Timestamp'] = ibi_df.apply(lambda x: format_time(x['Timestamp']) + '+00:00', axis=1)\n",
    "\n",
    "        ibi_all.append(ibi_df)\n",
    "    \n",
    "    ibi_df_all = []\n",
    "    ibi_df_all = pd.concat(ibi_all)\n",
    "    return ibi_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\shaye\\Documents\\EAT Lab\\Sensor_Data\"\n",
    "participant_data = glob.glob(base_path + \"/ID PR*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Timestamp       IBI Participant ID\n",
      "0   2020-12-15 13:59:22.234+00:00  0.812500          PR025\n",
      "1   2020-12-15 13:59:22.937+00:00  0.703125          PR025\n",
      "2   2020-12-15 13:59:23.625+00:00  0.687500          PR025\n",
      "3   2020-12-15 13:59:24.312+00:00  0.687500          PR025\n",
      "4   2020-12-15 13:59:25.031+00:00  0.718750          PR025\n",
      "..                            ...       ...            ...\n",
      "95  2021-01-13 14:41:59.578+00:00  0.468750          PR025\n",
      "96  2021-01-13 14:42:06.515+00:00  0.703125          PR025\n",
      "97  2021-01-13 14:42:14.812+00:00  0.453125          PR025\n",
      "98  2021-01-13 14:42:15.265+00:00  0.453125          PR025\n",
      "99  2021-01-13 14:42:15.703+00:00  0.437500          PR025\n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "for path in participant_data: \n",
    "    path_parts = path.split(\"\\\\\")\n",
    "    participant_id = path_parts[-1:][0].split()[-1:][0]\n",
    "    list_of_zips = glob.glob(path + \"/Empatica data/A*.zip\")\n",
    "    ibi_test = process_ibi(list_of_zips, participant_id)\n",
    "    print(ibi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:MYPASSWORD@localhost/E4Data', echo=False)\n",
    "with engine.begin() as connection:\n",
    "    df1 = ibi_test\n",
    "    df1.to_sql('IBI', con=connection, schema='EmpaticaStats', if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
